{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuchenhe/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Please create a new folder named \"all\" to store all txt files of threads in the original folder.\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import argparse\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from pandas import Series, DataFrame\n",
    "from pylab import rcParams\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import classification_report\n",
    "from graph_constructor import get_graph\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from one_course_vector import get_vector_for_one_course\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#course_id_list = []\n",
    "#course_vector_list = []\n",
    "\n",
    "#html-css-javascript LgWwihnoEeWDtQoum3sFeQ\n",
    "#python_database eQJvsjn9EeWJaxK5AT4frw\n",
    "#python_network Y4DUPDpQEeWO-Qq6rEZAow\n",
    "#python 7A1yFTaREeWWBQrVFXqd1w\n",
    "#hybrid-mobile-development -gcU5xn4EeWwrBKfKrqlSQ\n",
    "#machine-learning Gtv4Xb1-EeS-ViIACwYKVQ\n",
    "#learning-how-to-learn GdeNrll1EeSROyIACtiVvg\n",
    "#angular-js 52blABnqEeW9dA4X94-nLQ\n",
    "#server-side-development ngZrURn5EeWwrBKfKrqlSQ\n",
    "\n",
    "def read_forum_list(course_id):\n",
    "\n",
    "    forum_id_list = []\n",
    "    path = course_id + \"/\" + \"forum.txt\"\n",
    "    file = open(path, \"r\")\n",
    "    num_forum = int(file.readline())\n",
    "    for i in range (0, num_forum):\n",
    "        forum_id = file.readline()\n",
    "        forum_id = forum_id.rstrip(os.linesep)\n",
    "        forum_id_list.append(forum_id)\n",
    "        \n",
    "    return forum_id_list\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    course_vector_list = []\n",
    "    course_result_list = []\n",
    "    course_index_list = []\n",
    "    index = 0\n",
    "    database = input(\"Please input your database name: \")\n",
    "    course_id_list = []\n",
    "    path = \"courselist.txt\"\n",
    "    file = open(path, \"r\")\n",
    "    num_course = int(file.readline())\n",
    "    for i in range (0, num_course):\n",
    "        course_id = file.readline()\n",
    "        course_id = course_id.rstrip(os.linesep)\n",
    "        course_id_list.append(course_id)\n",
    "        course_index_list.append(index)\n",
    "        index += 1\n",
    "    \n",
    "    course_index_list = np.asarray(course_index_list)\n",
    "\n",
    "    kf = KFold(int(num_course), n_folds = 2, shuffle=False, random_state = 18)\n",
    "    print(kf)\n",
    "    #print(to_train)\n",
    "    for train_index, test_index in kf:\n",
    "        \n",
    "        train_set, test_set = course_index_list[train_index], course_index_list[test_index]\n",
    "        \n",
    "    for course_id in course_id_list:\n",
    "        forum_id_list = read_forum_list(course_id)\n",
    "        print(\"now\")\n",
    "        target_vector_list = get_vector_for_one_course(database, course_id, forum_id_list)\n",
    "        course_vector_list.append(target_vector_list[0])\n",
    "        course_result_list.append(target_vector_list[3])\n",
    "        print(target_vector_list[3])\n",
    "\n",
    "       \n",
    "\n",
    "        '''\n",
    "        sys_mat_train, sys_mat_test = course_vector_list[train_index], course_vector_list[test_index]\n",
    "        sys_result_train, sys_result_test = course_result_list[train_index], course_vector_list[test_index]\n",
    "        '''\n",
    "        \n",
    "    vec_train = []\n",
    "    for index in train_set:\n",
    "        each_mat = course_vector_list[index]\n",
    "        for each_vec in each_mat:\n",
    "            vec_train.append(each_vec)\n",
    "            \n",
    "    result_train = []\n",
    "    for index in train_set:\n",
    "        each_mat = course_result_list[index]\n",
    "        for each_vec in each_mat:\n",
    "            result_train.append(each_vec)\n",
    "            \n",
    "    vec_test = []\n",
    "    for index in test_set:\n",
    "        each_mat = course_vector_list[index]\n",
    "        for each_vec in each_mat:\n",
    "            vec_test.append(each_vec)\n",
    "            \n",
    "    result_test = []\n",
    "    for index in test_set:\n",
    "        each_mat = course_result_list[index]\n",
    "        for each_vec in each_mat:\n",
    "            result_test.append(each_vec)\n",
    "            \n",
    "    #LogReg = LogisticRegression(class_weight = 'balanced')\n",
    "    #LogReg.fit(x_train, y_train)\n",
    "    #y_pred = LogReg.predict(x_test)\n",
    "    \n",
    "    vec_train = np.asarray(vec_train)\n",
    "    result_train = np.asarray(result_train)\n",
    "    #print(vec_train.shape(0))\n",
    "    #print(vec_train.shape(1))\n",
    "    #print(result_train.shape(0))\n",
    "\n",
    "    vec_test = np.asarray(vec_test)\n",
    "    result_test = np.asarray(result_test)\n",
    "\n",
    "    LogReg = LogisticRegression(class_weight = 'balanced')\n",
    "    LogReg.fit(vec_train, result_train)\n",
    "    result_pred = LogReg.predict(vec_test)\n",
    "    with open('EDM.txt', 'w') as f:\n",
    "        print(classification_report(result_test, result_pred), file = f)\n",
    "    print(classification_report(result_test, presult_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input your database name: courseraData.db\n",
      "sklearn.cross_validation.KFold(n=5, n_folds=2, shuffle=False, random_state=18)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '52blABnqEeW9dA4X94-nLQ/forum.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-89026442c8a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-f7b42cb5807e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcourse_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcourse_id_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mforum_id_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_forum_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcourse_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"now\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mtarget_vector_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_vector_for_one_course\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcourse_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforum_id_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-f7b42cb5807e>\u001b[0m in \u001b[0;36mread_forum_list\u001b[0;34m(course_id)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mforum_id_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcourse_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"forum.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mnum_forum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_forum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '52blABnqEeW9dA4X94-nLQ/forum.txt'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
